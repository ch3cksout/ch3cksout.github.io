<H1>
  GPT emulating chess play: the dawn of poppycock engines
</H1>

<H2>
 TL;DR baseless claims notwithstanding, <u>LLMs cannot properly play chess</u>
  <p>- i.e. actually evaluate positions </u>
</H2>

<P>
I use this webpage to elucidate my thoughts on the recent hype-storm about the alleged chess playing ability by large language models, especially gpt-3.5-turbo-instruct.
I plan to release quantitative data relevant to the subject - something that has been on sorely low supply.
</P>

There is a lot of confusion about this, because GPT is excellent at pretending. Its algorithm completes text by adding tokens which make for sensible looking text
- without either the intent or the ability to check whether it is sensible. Superficially it appears as if GPT writes intelligently,
when in fact it generates bullshit.
<P>
 Likewise, given a prompt to invoke creating chess game notation (PGN code),
  GPT-based chess emulators complete move sequences by adding tokens which make for sensible looking PGN code
- without either the intent or the ability to check whether they are sensible chess moves.
  All the result presented so far indicate that, rather than the mysterious emergent chess ability some have claimed,
  we merely see the <a href="https://garymarcus.substack.com/p/the-imminent-enshittification-of">enshittification of the Internet </a> coming to the domain of chess. 
</P>
<P>
Much of the time the moves do happen to be sensible. But that is a happenstance caused by the training corpus (which includes the Internet)
 having had billions of chess games available in easily digestible PGN format.
 Regurgiating patterns learnt from that does not enable actual evaluation of positions.  
</P>

<P>
 For a different perspective, see the <a href="http://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/">post by Mathieu Acher</a>, with an excellent initial summary on the topic.
</P>

<P>
 And my own (still nascent) <a href="https://ch3cksout.github.io/xeets-and-that.html">writeup of debunking</a> is linked here.
</P>

